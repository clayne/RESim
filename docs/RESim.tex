\documentclass[titlepage]{article}
\usepackage{geometry}
\geometry{a4paper, total={170mm,257mm},left=20mm, top=10mm,}
\usepackage[colorlinks=true,linkcolor=blue,urlcolor=black]{hyperref}
\usepackage{bookmark}
\usepackage{graphicx}
\usepackage{titling}
\graphicspath{ {images/} }

\pretitle{%
  \begin{center}
  \LARGE
    \includegraphics[width=6cm]{resim.eps}\\[\smallskipamount]
}
\posttitle{\end{center}}
\begin{document}
\title {%
  RESim User's Guide \\
  \large Reverse Engineering heterogeneous networks of computers
   through external dynamic analysis}
\maketitle
\tableofcontents
\newpage

\section{Introduction}
Imagine you would like to analyze the processes running on computers within a network, including the programs they execute and the data they consume and exchange.   And assume you’d like to perform this analysis dynamically, but without ever running your own software on those systems and without ever having a shell on the systems.

RESim is a dynamic system analysis tool that provides detailed insight into processes, programs and data flow within networked computers.  RESim simulates networks of computers through use of the Simics\footnote{ Simics is a full system simulator sold by Intel/Wind River, which holds all relevant trademarks.} 
platform's high fidelity models of processors, peripheral devices (e.g., network interface cards), and disks.  The networked simulated computers load and run targeted software copied from disk images extracted from the physical systems being modeled.

RESim aids reverse engineering of networks of Linux-based systems by inventorying processes in terms of the programs they execute and the data they consume.  Data sources include files, device interfaces and inter-process communication mechanisms.   Process execution and data consumption is documented through dynamic analysis of a running simulated system without installation or injection of software into the simulated system, and without detailed knowledge of the kernel hosting the processes.

A RESim simulation can be paused for inspection, e.g., when a specified process is scheduled for execution, and subsequently continued, potentially with altered memory or register state.  The analyst can explicity modify memory or register content, and can also dynamically augment memory 
based on system events, e.g., change a password file entry as it is read by the {\tt su} program (see \ref{dmod}.

RESim also provides interactive analysis of individual executing programs through use of the IDA Pro
disassembler/debugger to control the running simulation.  The disassembler/debugger
allows setting breakpoints to pause the simulation at selected events in either future time, or past time.  For 
example, RESim can direct the simulation state to reverse until the most recent modification of a selected memory address.   During a RESim session,
any point within the simulation can be \textit{bookmarked}, and that execution state can later be restored.  Within this document, this action is referred
to as \textit{skipping the simulation} to that bookmarked execution point.

Reloadable checkpoints may be generated at any point during system execution, and these checkpoints can then be used as the starting point of future RESim 
sessions.  These checkpoints include the full target system state (e.g., similar to a VM snapshot) as well as RESim context information such as
information about currently running processes.
  
Analysis is performed entirely through external observation of the simulated target system's memory and processor state, 
without need for shells, software injection, or kernel symbol tables.   The analysis is said to be \textit{external} because the observation functions do
not affect the state of the simulated system \footnote{See \ref{external} for an example of the implications}.

\section{Analysis artifacts}
RESim generates system traces of all processes on a computer, starting with system boot, or from a selected checkpoint.  Trace reports include two components: 
\begin{enumerate}
\item A record of system calls, identifying the calling process and selected parameters, e.g., names of files and sockets and IP addresses.
\item A process family history for each process and thread that has executed, identifying:
\begin{enumerate}
\item Providence, i.e., which process created the process (or thread), and what programs were loaded via the {\tt execve} system call.
\item Files and pipes that had been opened (including file descriptors inherited from the parent), and those that are currently open.
\item Linux socket functions, e.g. , connect, accept, bind, etc.  Socket connect attempts to external components are highlighted, as are 
externally visible socket accepts.
\item Mapped memory shared between processes
\end{enumerate}
\end{enumerate}

The system trace is intended to help an analyst identify programs that consume externally shaped data.  Such programs can then be analyzed in depth with the dynamic disassembler. [TBD expand to support decompilers where available].  

Artifacts associated with individual processes (and their associated threads) include:
\begin{itemize}
\item Maps of shared object libraries loaded by each thread, including their load addresses
\item Records of references to input data, including copies of such data, as the target program consumes the data.  These \textit{Watch Marks}, 
(see \ref{tracking}), can be dynamically loaded to skip the simulation to the point of the reference.
\item Reverse data tracks that trace sources of memory or register values in terms of exchanges between memory and registers, potentially leading
back to initial ingest of the data, e.g., via a recv system call.
\item Data written to selected files or file descriptors, (see the {\tt traceFile/traceFD} commands.
\item System traces as previously described, but constrained to actions taken by threads within the process being analyzed.
\end{itemize}

\section{Dynamic analysis of programs executing in their environment}
RESim couples an IDA Pro disassembler debugger client with the Simics simulation to present a dynamic view into a running process.  The analyst sets breakpoints and navigates through function calls in both the forward and reverse execution directions.  This facilitates tracking the sources of data.  For example, if a program is found to be consuming data at some location of interest, reverse execution might identify a system call that brings the data into the process’s address space.

A key property that distinguishes RESim from other RE strategies is that analysis occurs on processes as they execute in their native environment, and as they interact with other processes and devices within the system.  Consider an example process that communicates with a remote computer via a network while also interacting with a local process via a pipe.  When the analyst pauses RESim for inspection, the entire system pauses.  The simulation can then be resumed (or single-stepped) from the precise state at which it was paused, without having to account for timeouts and other temporal-based discontinuities between the process of interest and its environment.

\section{Limitations}
RESim analyzes Linux-based systems for which copies of bootable media or root file systems can be obtained.  Analysis does not depend on a system map of the kernel, i.e., it works with stripped kernel images.  The current version of RESim supports 32-bit and 64-bit X86 and 32-bit ARM.  It can also be 
extended to support alternate architectures, e.g., 64-bit ARM, supported by Simics processor models \footnote{A summary of Simics device models is at: \url{https://www.windriver.com/products/simics/simics-supported-targets.html}}.  RESim is currently limited to single-processor (single core) models.  Simics supports
multi-processor simulations (at reduced performance), but RESim has not yet been extended to monitor those.


\section{Workflow}
Simulated systems are defined within RESim configuration files (see \ref{configuration} that  parameterize pre-defined Simics scripts to identify 
processors and interface devices, e.g., network cards, disks and system consoles.  RESim currently includes the following platforms: 
\begin{itemize}
\item A general purpose X86 platform with disk, multiple ethernet and serial ports;
\item A generic ARM Cortex A9 platform with disk, multiple ethernet and serial ports.
\item An ARMV5 platform based on the ARM926EJ-S processor.  This is a partial implementation of the ARM Integrator-CP board.  It currently only supports
the initial RAM disk, one ethernet and serial ports.
\end{itemize}

Other platforms can be modeled via Simics, the detailes of which are beyond the scope of this manual.
Once a system is modeled and referenced by a RESim configuration file, a RESim script is run, naming the configuration file.

RESim analysis requires about twenty parameters that characterize the booted kernel instance, e.g., offsets within task 
records and addresses of selected kernel symbols.  The CREATE\_RESIM\_PARAMS directive within the RESim configuration file directs the tool to automatically analyze the running kernel 
and extract the desired parameters.  This allows RESim to analyze disparate Linux kernels without a priori 
knowledge of their versions or configurations \footnote{Not to be confused with the similar function included with Simics Analyzer product. RESim uses an alternate strategy for OS-Awareness.}.
See section \ref{getting-started}.

Once the kernel parameters have been extracted, the RESim configuration file is modified to reference the parameter file, and the simulation is restarted. The user is
presented with a command line interface console.  This console manages the simulation via a combination of RESim and Simics commands, including commands to:
\begin{itemize}
\item Start or stop (pause) the simulation
\item Run until a specified process is scheduled
\item Run until a specified program is loaded, i.e., via execve
\item Generate a system trace
\item Inspect memory and component states
\item Enable reverse execution, i.e., allow reversing to events from that point forward
\item Set and run to breakpoints, either in the future or in the past.
\item Target RESim to focus on a specific process thread group, e.g., for dynamic analysis using IDA Pro.
\end{itemize}
\noindent See section \ref{commands} for details of RESim commands.

When RESim is targeted for a given process it runs until that process is scheduled, after which the user starts IDA Pro with a suite of custom plugins that interact with the simulation.  If a binary image of the target program is available, standard IDA Pro analysis functions are performed.  If no program image is available, IDA Pro will still present disassembly information for the program as it exists in simulated system memory.  

RESim extends IDA Pro debugger functions and the analyst accesses these functions via menus and hot keys.   The disassembler/debug client can be used to:
\begin{itemize}
\item Single-step through the program in either the forward or reverse direction
\item Set and run to breakpoints in either direction
\item Run to the next (or previous) system call of a specified type, e.g., open.
\item Run to system calls with qualifying parameters, e.g., run until a socket connect address matches a given regular expression.
\item Reverse-trace the source of data at a memory address or register.
\item Modify a register or memory content
\item Switch threads of a multithreaded application
\item Set and jump to bookmarks
\end{itemize}

\subsection{Find interesting processes}
A typical strategy with RESim is to initially perform a full system trace on a system as a means of identifying programs of interest, e.g., which can then be
further analyzed using the interactive IDA Pro client.  The {\tt traceAll} command described below in \ref{commands} generates such a trace.  Note that a typical Linux-based
system can perform tens of thousands of system calls during initial boot processing.  It may save considerable time to use the {\tt toProc} command to run forward to some
event such as creation of {\tt rsyslogd} before issuing the {\tt traceAll} command.  Note that {\tt toProc} tracks processes creation and some system configuration settings such as
IP addresses set using {\tt ip} or {\tt ifconfig} commands, which can be seen using the {\tt showNets} command.  Use the {\tt writeConfig} command to create a checkpoint,
and then update your ini file to begin at that checkpoint using the {\tt RUN\_FROM\_SNAP} directiv.  Trace files are created in the /tmp directory.  During a trace, if you use the Simics stop and
run commands, the tracing will continue.  While stopped, you may use the {\tt tasks} commands to see which processes are currently running.  Or the {\tt showBinders} command to 
see network ports being listened to. See \ref{example-workflows} for more detailed examples of RESim workflows.

\section{Development and Availability}
In addition to running on a local Simics installation, RESim is intended to be offered as a network service to users running local copies of IDA Pro and an SSH session with a RESim console.  See the \textit{RESim Remote Access Guide}.  The tool is derived from the “Cyber Grand Challenge Monitor” (CGC), developed by the Naval Postgraduate School in support of the DARPA CGC competition.  
RESim is implemented in Python, primarily using Simics breakpoints and callbacks, and does not rely on 
Simics “OS Awareness” or Eclipse-based interfaces.   IDA Pro extensions are implemented using IDAPython.  
All of the RESim code is available on github at \url{https://github.com/mfthomps/RESim}


\section{RESim commands}
\label{commands}
The following RESim commands are issued at the Simics command prompt, naming the commands as methods of the {\tt cgc} python module,
e.g., "{\tt @cgc.tasks()}".

\label{commands}
\begin{itemize}
\item {\tt tasks} -- List currently executing process names and their PIDs.
\item {\tt traceProcesses} – Begin tracing the following system calls as they occur:
vfork; clone; execve;  open; pipe; pipe2; close; dup; dup2; socketcall; exit; group\_exit
Tracing continues until the stopTrace command is issued.  Also see \ref{postprocessing}

\item {\tt toProc} – Continue execution until the named program is either loaded via execve or scheduled.  Intended for use prior to tracing processes, e.g., to get to some known point before incurring overhead associated with tracing.   This function will track processes PIDs and names along with network configuration information, and will save that data if a writeConfig function is used.

\item {\tt writeConfig} – Uses the Simics write-configuration command to save the simulation state for later loading with read-configuration.  This wrapper also saves process naming information, shared object maps and network configuration commands for reference subsequent to use of the read-configuration function.

\item {\tt traceAll} – Begin tracing all system calls.  If a program was selected using debugProc as described below, limit the reporting to that process and its threads.  Also see \ref{postprocessing}

\item {\tt showProcTrace} – Generate a process family summary of all processes that executed since the traceProcess (or traceAll) command.

\item {\tt showNets} – Display network configuration commands (e.g., {\tt ifconfig} collected from process tracing and the use of toProc.

\item {\tt showBinders} – Display programs that use bind and accept socket calls – intended for use during process tracing to identify processes that listen on externally accessible sockets.

\item {\tt showConnectors} – Display programs that use connect to open sockets – intended for use during process tracing to identify processes that connect to externally accessible sockets.

\item {\tt traceFile(logname)} – Copy all writes that occur to the given filename.  Intended for use with log files.  Output is in /tmp/[basename(logname)]

\item {\tt traceFD(FD)} – Copy all writes that occur to a given FD, e.g., stdout.  Output is in /tmp/output-fd-[FD].log  

\item {\tt flushTrace} - Flush trace output to the trace log files.

\item {\tt debugProc(process name)} – Initiate the debugger server for the given process name.  If a process matching the given name is executing, system state advances until the process is scheduled.  If no matching process is currently executing, execution proceeds until an execve for a matching process.   If a copy of the named program is found on the RESim host, (i.e., to read its ELF header), then execution continues until the text segment is reached.  RESim tracks the process as it maps shared objects into memory (see Appendix C).  The resulting map of shared object library addresses is then available to the user to facilitate switching between IDA Pro analysis and debugging of shared libraries and the originally loaded program.

Subsequent to the debugProc  function completion, IDA Pro can be attached to the simulator.  Most of the commands listed below have analogs available from within IDA Pro, once the RESim {\tt rev.py} plugin is loaded.

If execution transfers to a shared object library of interest, the associated library file can be found via the getSOFile command described below.  Load that file into IDA Pro and rebase to the SO address
found via showSOMap prior to attaching the debugger.  If you have run reTrack or injectIO, you must re-run the command in order for the Watch Marks to 
detect and report mem operations, e.g., memcpy -- and then refresh the IDA Data Watch window. 

If you prefix the given process name with {\tt sh }, (sh followed by a space), RESim will look for a shell invocation of the script name that follows the sh.

\item {\tt runToSyscall(call number)} – Continue execution until the specified system call is invoked.  If a value of minus 1 is given, then any system call will stop execution.  If the debugger is active, then execution only halts when the debugged process makes the named call.

\item {\tt runToConnect(search pattern)} – Continue execution until a socket connection to an address matching the given search pattern.

\item {\tt runToBind(search pattern)} – Continue execution until a socket bind to an address matching the given search pattern.  Alternately, providing just
a port number will be translated to the pattern {\tt .*:N} where N is the port number.

\item {\tt runToAccept(FD)} – Continue execution until a return from a socket accept to the given file descriptor.

\item {\tt runToIO(fd, nth=1)} – Continue execution until a read or write to the given file descriptor.  If nth is greater than 1, will run until
the nth recv call.

\item {\tt clone(nth)} – Continue execution until the nth clone system call in the current process occurs, and then halt execution within the child.

\item {\tt runToText()} – Continue execution until the text segment of the currently debugged process is reached.  This, and revToText, are useful after execution transfers to libraries, or Linux linkage functions, e.g., references to the GOT.

\item {\tt revToText()} – Reverse execute the current process until the text segment is reached.
 
\item {\tt showSOMap(pid)} – Display the map of shared object library files to their load addresses for the given pid (along with the main text segment).

\item {\tt getSOFile(pid, addr)} – Display the file name and load address of the shared object at the given address.

\item {\tt revInto} – Reverse execution to the previous instruction in user space within the debugged process. 

\item {\tt revOver} – Reverse execution to the previous instruction in the debugged process – without entering functions, e.g., any function that may have returned to the current EIP.  Note that ROP may throw this off, causing you to land at the earliest recorded bookmark.  Use {\tt revInto} to reverse following a ROP.

\item {\tt uncall} – Reverse execution until the call instruction that entered the current function.

\item {\tt precall([pid]} - Reverse until prior to system call for given or current PID.  
Note that this, like all reversing calls, assumes you have recorded time into which you can reverse\footnote{This command previoulsy was manually combined
with trackIO in cases where the read was waiting in the kernel.  That logic has now been combined into trackIO.}

\item {\tt revToWrite(address)} – Reverse execution until a write operation to the given address within the debugged process.

\item {\tt revToModReg(reg)} – Reverse execution until the given register is modified.

\item {\tt revTaintReg(reg)} – Back trace the source of the content the given register until either a system call, or a non-trivial computation (for evolving definitions of “non-trivial”.  

\item {\tt revTaintAddr(addr)} -- Back trace the source of the content the given address until either a system call, or a non-trivial computation

\item {\tt runToUser()} – Continue execution until user space of the current process is reached.

\item {\tt reverseToUser()} – Reverse execution until user space of the current process is reached.

\item {\tt setDebugBookmark(mark)} – set a bookmark with the given name.

\item {\tt goToDebugBookmark} – jump to the given bookmark, restoring execution state to that which existed when the bookmark was set.

\item {\tt watchData} – run forward until a specified memory area is read.  Intended for use in finding references to data consumed via a read system call.  Data watch parameters are automatically set on a read during a debug session, allowing the analyst to simply invoke the watchData function to find references to the buffer.  List data watches using {\tt showDataWatch}.
Note however, that data watches are based on the len field given in the read or recv, and thus data references are not necessarily to data actually read (e.g., a read of ten bytes
that returns one byte would break on a reference to the fifth byte in the buffer.)

\item {\tt trackIO(FD)} -- Combines the {\tt runToIO} and the {\tt watchData} functions to generated a list of data watch bookmarks that indicate execution
points of relevant IO and references to received data.  This list of bookmarks is displayed using {\tt showWatchMarks} or in the IDA client {\tt data watch} window (right click and refresh).
The trackIO function will break simulation after {\tt BACK\_STOP\_CYCLES} with no data references. If the debugged processes are in the kernel waiting to read on the given
FD, RESim will back up to prior to the system call before proceeding.  This insures the very next received data is tracked. Data watches persist after the
call, e.g., to support {\tt retrack} described below.  Each use of trackIO will reset all data watches, but does not clear watch marks, i.e., you can still skip to those simulation cycles.  Also see 
the {\tt tagIterator} command.

\item {\tt retrack} -- Intended for use after modifying content of an input buffer in memory.  This will track accesses to the input buffer.
Note that this function does record additional IO operations, BUT WILL reflect subsequent access to the existing watch buffers.  (TBD, terminate on access
to remembered FD?)

\item {\tt trackFile} -- Currently works only with files opened by xmlParseFile. The function notes all memory malloc'd within
xmlParseFile and then tracks its access, e.g., via xmlGetParam, adding Watch Marks as it goes.

\item {\tt goToDataMark(watch\_mark)}  Skip to the simulation cycle associated with the given {\tt watch\_mark}, which is an index into the list of
data watch bookmarks generated by {\tt trackIO}.

\item {\tt getWatchMarks()} Return a json list of watch marks created by watchData or trackIO.

\item {\tt tagIterator} Tag a watch mark as being an iterator.  The associated function is added to a file stored along with IDA functions
The intent is to avoid data watch events on each move, or access, e.g., a crc generator.

\item {\tt trackFunctionWrite(fun)} Record all write operations that occur between entry and return from the named function.

\item {\tt goToWriteMark(write\_mark} Skip to the simulation cycle associated with the given {\tt write\_mark}, which is an index into th elist of 
write watch bookmarks generated by {\tt trackFunctionWrite}.

\item {\tt getWriteMarks()} return a json list of write marks created by {\tt trackFunctionWrite}.

\item {\tt injectIO(iofile, stay=False)} -- Assumes you have previously used trackIO or otherwise have a Watch Mark corresponding to receiving data
into a buffer.  The simulation will skip back to that Watch Mark and the content of the given {\tt iofile} is 
written into the read buffer, and the register reflecting 
the count is modified to reflect the size of the file.  If {\tt stay} is False, the {\tt retrack} function is then invoked.  Intended use is to rapidly observe execution paths for variations in
input data.   *** TBD *** Limit count based on what was previously read -- i.e., do not mod r1.  We do not know length passed in in to call  -- unless
recorded in the Watch Mark?

\item {\tt traceInject(iofile)} -- Similar to injectIO, but performs a traceAll instead of tracking IO.

\item {\tt showThreads} - List the thread PIDs of the process being debugged.

\item {\tt getStackTrace} – shows the call stack as seen by the monitor.  The Ida client uses this to maintain its view of the callstack.  The monitor
uses the IDA-generated function database ({\tt .fun} files stored wtih the {\tt .idb} files to aid in determining if 
potential instruction calls are to functions.  The monitor-local {\tt stackTrace} command displays a
stack trace that uses the IDA function database to resolve names.  (TBD, does not yet handle plt, and thus shows call addresses for such calls).
This function is not always reliable, e.g., phantom frames may appear based on calls that occurred previously.

\item {\tt writeReg} – Write value to a register (Note: deletes existing bookmarks.)
\item {\tt writeWord} – Write word to an address. This function will delete existing bookmarks and craete a new origin.  If there are data watch marks,
i.e., from a trackIO, these are deleted except for any that are equal to the current cycle.  The upshot of this is that if you want to modify memory
and then rerun a trackIO, do so while at the first datamark.
\item {\tt writeString} - Write a string to an addrss. Use double escapes, e.g., two backslashes and an n for a newline. (Note: deletes existing bookmarks.)

\item {\tt runToDmod()} – Run until a specified read or write system call is encountered, and modify system memory such
that the result of the read or write is augmented by a named Dmod directive file.  See \ref{dmod}

\item {\tt setTarget} -- Select which simulated component to observe and affect with subsequently issued commands.  Target names are as defined in the
RESim configuration file used to start the session.

\item {\tt saveMemory(addr, size, fname)} Write a byte array of the given size read from the given addr into a file with the given name.

\item {\tt runToKnown} Continue execution until a text range known to the SOMap (see {\tt showSOMap()}).  Intended for use if execution stops in got/plt 
or other loader goo.

\item {\tt runToOther} Continue execution until a text range known to the SOMap (see {\tt showSOMap()}) -- but not the current text range -- is entered.
Useful if you are in some library called by some other library, and you want to return to the latter.

\item {\tt modFunction(fun, offset, word)} Write the given word at an offset from the start of the named function.  Intended for use in setting return
values, e.g., force eax to zero upon return.  Bring your own machine code.  TBD accept an assembly statement?

\item {\tt catchCorruption} – Watch for events symptomatic of memory corruption errors, e.g., SEGV or SIGILL exceptions resulting from buffer overflows.  This is automatically enabled during debug sessions. Refer to \ref{SEGV} for information about what we mean by SEGV, and how we catch it.

\item {\tt watchROP} -- Watch for return instructions that do not seem to follow calls.  This is available while debugging a process.

\item {\tt autoMaze} -- Avoid being prompted when tracing detects a crude timing loop or other events that are repeated many times in a loop.
See section \ref{maze}.

\item {\tt mapCoverage} -- Set breakpoints on all basic blocks in the text segment and use them to track code coverage. The basic block coverage is
saved in a <prog>.hits file in IDA db directory, and will be read by the IDA client colorBlocks script   Subsequent uses of this command
will reset the coverage tracking.  Use {\tt stopCoverage} to stop basic block tracking.  The basic blocks database is read from the .blocks file created
by the IDA client findBlocks script.  See section \ref{coverage} for information on how the IDA client represents code coverage and highlights
branches that have not been taken.

\item {\tt showCoverage} -- display summary of basic block coverage.  Also see the IDA client {\tt color blocks} command and see the resetBlocks.py script.

\item{\tt goToBasicBlock} -- Skip the simulation state to the first hit of the block named by an address (requires use of {\tt mapCoverage}..

\item{\tt fuzz(IOFile} -- Assume the simulation is at a return from a read, set basic block coverage and iteratively execute while reducing the
IOFile data size (padding with nulls) until a minimum is found.  The final file in {\tt /tmp/trimmer} is truncated and may need to be padded to be properly consumed, e.g.,
if the program insists on reading a minimum number of bytes.  Intende for use in preparing minimal seed files for AFL.

\item{\tt afl()} -- Uses a netwok connection of localhost:8765 with an AFL server (githum/mfthomps/AFL).  The simulation is assumed to be stopped on a return
from the read of interest.  Multiple reads are not yet handled.

\item{\tt satisfyCondition} -- (experimental) Assess the comparison instruction at a given address and attempt to satisfy it by altering input data.  
Initially handles simple ARM {\tt cmp reg, <value>} instructions.  The 
reverse track function is used to determine the source of the register content, and if that is a receive, it alters the data to satisfy the
comparison and then uses {\tt retrack} to run forward and track the new execution flow.

\item {\tt idaMessage} -- display the most recent message made available to IDA.  For example, after a runToBind, this will display the FD that was bound to.

\item {\tt traceMalloc} -- track calls to the malloc and free functions and includes those events in the list of Watch Marks. Uuse {\tt showMalloc} to 
then list by pid, block address and size.

\end{itemize}

\subsection{Postprocessing}
\label{postprocessing}
See the scripts in {\tt RESim/postscripts} to parse system call logs and create reports on file, network and IPC (System V) usage.

\section{Defining a target system}
\label{configuration}
This section assumes some familiarity with Simics.  RESim is invoked from a Simics workspace that contains a RESim configuration file.
This configuration file identifies disk images used in the simulation and defines network MAC addresses.  
The file uses {\tt ini} format and has at least two sections: and {\tt ENV} section and one section per computer that will be part
of the simulation.  An example RESim configuration file is at:
\begin{verbatim}
$RESIM/simics/workspace/mytarget.ini
\end{verbatim}

\subsection{ENV section}
The following environment variables are defined in the {\tt ENV} section of the configuration file:
\begin{itemize}
\item {\tt RUN\_FROM\_SNAP} The name of a snapshot created via the {\tt @cgc.writeConfig} command.
\item {\tt RESIM\_TARGET} Name of the host that is to be the target of RESim analysis.  Currently only one host can be analyzed during a given
\item {\tt CREATE\_RESIM\_PARAMS} If set to {\tt YES}, the getKernelParams utility will be run instead of the RESim monitor.  This will
generate the Linux kernel parameters needed by RESim.  Use the {\tt @gkp.go()} command from the Simics command prompt to generate the file.
\item {\tt DRIVER\_WAIT} Causes RESim delay boot of target platforms (i.e., those other than the driver) until the 
user runs the {\tt @resim.go()} command.  Intended to allow you (or scripts)
to configure the driver platform after it boots, but before other platforms will boot.
\item {\tt BACK\_STOP\_CYCLES} Limits how far ahead a simulation will run after the last data watch event.
\item {\tt MONITOR} If set to NO, monitoring is not performed.
\item{\tt INITIAL\_SCRIPT} Simics script to be run using run-command-file.  For example, use this to attach real networks to avoid
doing so after enabling reverse execution (which should be avoided due to Simics foibles).
\end{itemize}

\subsection{Target sections}
Each computer within the simulation has its own section. The section items listed below that 
have a {\tt \$} prefix represent Simics CLI variables used within Simics scripts.  If you define your own
simics scripts (instead of using the generic scripts included with RESim), you may add arbitrary CLI variables
to this section. 
\begin{itemize}
\item {\tt \$host\_name} Name to assign to this computer.
\item {\tt \$use\_disk2} Whether a second disk is to be attached to computer.
\item {\tt \$use\_disk3} Whether a third disk is to be attached to computer.
\item {\tt \$disk\_image} Path to the boot image for the computer.
\item {\tt \$disk\_size} Size of disk\_image
\item {\tt \$disk2\_image} Path to the 2nd disk
\item {\tt \$disk2\_size} Size of 2nd disk\_image
\item {\tt \$disk3\_image} Path to the 3nd disk
\item {\tt \$disk3\_size} Size of 3nd disk\_image
\item {\tt \$mac\_address\_0} Enclose in double quotes
\item {\tt \$mac\_address\_1} Enclose in double quotes
\item {\tt \$mac\_address\_2} Enclose in double quotes
\item {\tt \$mac\_address\_3} Enclose in double quotes
\item {\tt \$eth\_device} Alternet ethernet device, see \ref{networks} below.

\item {\tt SIMICS\_SCRIPT} Path to the Simics script file that defines the target system.  This path is relative to the {\tt target} directory
of either the workspace, or the RESim repo under {\tt simics/simicsScripts/targets}.  For example, 
\begin{verbatim}
SIMICS_SCRIPT=x86-x58-ich10/genx86.simics
\end{verbatim}
\noindent would use the generic X86 platform distributed with RESim.
\item {\tt OS\_TYPE} Either LINUX or LINUX64
RESim session.
\item {\tt RESIM\_PARAM} Name of a parameter file created by getKernParams utility.
\item {\tt RESIM\_UNISTD} Path to a Linux {\tt unistd*.h} file that will be parsed to map system call numbers to system calls.
\item {\tt RESIM\_ROOT\_PREFIX} Path to the root of a file system containing copies of target executables.  This is used by RESim read elf
headers of target software and to locate analysis files generated by IDA Pro. 
\item {\tt BOOT\_CHUNKS} The number of cycles to execute during boot between checks to determine if the compnent has booted enough to track
its current task pointer.  The intent is to keep this value low enough catch the system shortly after creation of the initial process.
The default value is 900,000,000, which is too large for some ARM implementations.  While components are booting, RESim uses the smallest
{\tt BOOT\_CHUNKS} value assigned to any component that has not yet completed its boot.
\item {\tt DMOD} Optional file to pass to the {\tt runToDmod} command once the component has booted.  See \ref{dmod}.
\item {\tt PLATFORM} One of the following: x86; arm; or arm5
\end{itemize}

\subsection{Network definitions}
\label{networks}
Three network switches are created, named switch0, switch1 and switch2.   Each generic RESim computer has one or more network interfaces,
depending on the type of platform.
These are named eth0, eth1 and and eth2, and are assigned corresponding MAC addresses from the
RESim configuration file. By default, each computer ethernet interface is connected to its correspondingly numbered switch.
This topology may be modified via entries in computer sections of the RESim configuration file.  For example, an entry of:
\begin{verbatim}
ETH0_SWITCH=switch2
\end{verbatim}
\noindent would connect the eth0 deivce to switch2.  A switch value of {\tt NONE} prevents the ethernet device from being connected
to any switch.  Note there is no error checking or sanity testing.  In the above example, you would also need to re-assign the eth2 device
or it will attempt to attach two connections to the same switch port.

Ethernet devices on the generic x86 platform default to the {\tt i82543gc} device defined by Simics.  Use of the {\tt \$eth\_dev=} 
entry lets you pick one of the following alternate ethernet devices:
\begin{verbatim}
i82559
i82546bg
i82543gc
\end{verbatim}

Simics CLI variables are assigned to each computer ethernet link using the convention {\tt \$TARGET\_eth0} where {\tt TARGET}
is the value of the configuration file section header for that component.  Similarly, connections from the computer to the switches 
are named using the convention {\tt \$TARGET\_switch0}.  These CLI variable names may be referenced in user-supplied scripts, or in 
Dmod directives of type {\tt match\_cmd}.  See \ref{dmod}.

The {\tt eth1} cli name is assigned to the motherboard ethernet slot. the eth0, eth2 get northbridge slots and eth3 gets a southbridge pci slot.

\subsection{Driver component}
Each simulation can have an optional driver component -- designated by assigning the string {\tt driver} to the corresponding
section header.  This component will be created first, and other components will not be created until the driver has
caused a file named {\tt driver-ready.flag} to be created within the workspace directory.  Use the Simics Agent to 
create that file from the driver computer.  This requires you copy the Simics agent onto the target and get it to run
upon boot.  It is intended that the agent will load scripts to generate traffic for the target computers.  See section
\ref{driver} for information on updating driver platforms.

\section{Running the simulation}
RESim sessions are started from the Simics workspace using the \$RESIM/simics/monitorCore/launchRESim.py program,
where {\tt \$RESIM} is a path to the RESim repo.  That program requires some environment variables, which are typically
set in a bash script, an example of which is in
\begin{verbatim}
$RESIM/simics/workspace/monitor.sh
\end{verbatim}
\noindent Modify that script to name the path to your RESim repo. (The {\tt montitor5.sh} version works with Simics 5.)

\subsection{Installation}
RESim assumes you have installed and are somewhat familiar with Simics.  Versions 4.8 and 5.0 are supported.
It also assumes you have IDA Pro.
\begin{itemize}
\item Get RESim from the git repo:
\begin{verbatim}
   git clone https://github.com/mfthomps/RESim.git
\end{verbatim}
\item Install python-magic from gz file:  pip install <path>
\begin{verbatim}
   sudo pip install /mnt/re_images/python_pkgs/python-magic-0.4.15.tar.gz
\end{verbatim}
\item Install xterm
\begin{verbatim}
    apt-get install xterm
\end{verbatim}
\item In your ~/idaxx/cfg directory, there are a number of xml files that need to be replaced with those found
in {\tt simics/ida/cfg}.  Backup the original xmls first.
\end{itemize}
\subsection{Getting started}
\label{getting-started}
Steps to define and run a RESim simulation are listed below.  It is assumed you are familiar with basic Simics concepts and have a
computer upon which Simics is installed with a x86-x58-ich10 platform.
\begin{enumerate}
\item Create a Simics workspace, e.g.,
\begin{verbatim}
mkdir mywork; cd mywork
../install/simics-5/simics-5.0.185/bin/project-setup
\end{verbatim}

\item Copy files from {\tt \$RESIM/simics/workspace} into the new workspace.
\item Clone the RESim repo 
\item Modify the monitor.sh script to reflect your Simics installation and the path to your RESim repo.
\item Modify the mytarget.ini as follows:
\begin{itemize}
\item Set the {\tt disk\_image} entry to name paths to your target disk image.
\item Obtain the {\tt unistd\_32.h} or equivalent, for your target's kernel -- this is used match system call numbers to calls.  Name
the file in the {\tt RESIM\_UNISTD} parameter.
\item Copy the target systems root file system, or a subset of the file system containing binaries of interest to the local computer
and name that path in the {\tt RESIM\_ROOT\_PREFIX} parameter.  These images are used when analyzing specified programs, and are given
to IDA Pro for analysis.
\item Set the {\tt CREATE\_RESIM\_PARAMS} parameter to YES so that the first run will create the kernel parameter file needed by RESim.
\end{itemize}
\item Launch RESim using {\tt ./monitor.sh mytarget}.  That will start Simics and give you the Simics command prompt.
\item  Continue the simulation until the kernel appears to have booted, then stop.
\item Use the {\tt @gkp.go()} command to generate the parameter file.  This may take a while, and may require nominial interaction
with the target system via its console, e.g., to schedule a new process.  If it displays a message saying it is not in the kernel,
try running ahead a bit, e.g., {\tt r 10000} and try the gkp.go command again.
\item After the parameters are created, quit Simics and remove the {\tt CREATE\_RESIM\_PARAMS} parameter.
\item Restart the monitor.sh.  RESim will begin to boot the target and pause once it has confirmed the current task record.  You
may now use RESim commands listed in \ref{commands}.
\end{enumerate}

\subsubsection{Kernel Parameters for 32-bit compatability}
If a 64-bit Linux environment incudes 32-bit applications, first create kernel parameters per the above, and then run until one of the 32-bit applications
is scheduled and use @cgc.writeConfig to save
the state.  Modify the ini file to restore that state and set CREATE\_RESIM\_PARAMS to YES.  Then start the monitor and use
{\tt @gkp.compat32()}.  This will modify the kernel parameters in the .param file to include those needed to monitor 32-bit applications.

\subsection{IDA Pro}
\label{ida}
Once you have identified a program to be analyzed, e.g., by reviewing a system trace, open the program in IDA Pro at the location relative to the 
{\tt RESIM\_ROOT\_PREFIX} path named in the RESim configuration file.  

The first time you start IDA, use the {\tt Debugger / Process options} to ensure your host is localhost and the port is 9123.  Save those as 
the default.  Then go the {\tt Debugger setup} and select {\tt Edit exceptions}.  Change the SIGTRAP entry to pass the signal to the application;
and to only log the exception.  Save the settings.  You should only need to do this step once.

The first time you open a given program in IDA, run this script (from File / Script file):
\begin{verbatim}
$RESIM/simics/ida/dumpFuns.py 
\end{verbatim}
\noindent This will create a data file used by RESim when generating stack traces.
You may also run the {\tt findBlocks.py} script to generate a database of basic blocks that will be read by the RESim {\tt mapCoverage} command.
This will then track basic block coverage, and that can be highlighted using the {\tt colorBlocks.py} script.

From the Simics command line (after starting RESim), run the {\tt @cgc.debugProc<program>} command, naming the program of interest.
RESim will continue the simulation until the program is {\tt exec}'ed and execution is transferred to the text segment, at which point it will pause.
Using {\tt debugProc} rather than {\tt debugPid} allows RESim to collect shared object information for the target process.
You may now attach the IDA gdb debugger to the process.   After the debugger has attached, run this IDA plugin script:
\begin{verbatim}
$RESIM/simics/ida/rev.py
\end{verbatim}
You can now run the commands found in the debugger help menu.  Note those commands generally invoke RESim commands listed in \ref{commands}.

Note the RESim IDA client is not a robust debug environment in the sense that you can easily have Simics leave your intended execute context.
There are attempts to catch the termination of the process being debugged.  But in general, you should consider defining bookmarks to enable you to
return to a known state.  

There are situations where it is most productive, or necessary, to enage with the Simics command line directly.  If you change the execution state
via the command line, you can get IDA back in synch via the {\tt Debugger / Resynch with server} menu selection.

RESim commands are available in IDA via the Debugger menu item, and via right clicking on addresses.  

\subsection{Dynamic modifications to memory and topology}
\label{dmod}
RESim includes functions that dynamically modify modeled elements and connections,
triggered by system events.  For example, a script that loads selected kernel modules could be augmented in memory to
load alternate modules, e.g., those for which you have modeled devices.  Modifying such a script on the volume
image itself is not always convenient, e.g., \textit{tripwire} functions might manage checksums of
configuration files.  It is therefore sometimes preferable to dynamically augment the software's perception of what is read.

The {\tt runToDmod} function triggers on the reading or writing of a specified
regular expression via the {\tt write} or {\tt read} system calls.  
The {\tt runToDmod} function includes a parameter that names a file containing
Dmod directives.  In all subfunctions listed
below, the {\tt match} string identifies the read or write operation that triggers the action. 
The format of directive files depend on the subfunction.  Each subfunction also identifies whether it is
triggered on a {\tt read} or {\tt write} operation. 
 
\begin{itemize}
\item {\tt sub\_replace <operation>}-- Replace a substring within a read or write buffer (specified by the
{\tt <operation>}, with a given string.
The directives file includes one or more sets of directives.
The directives use regular expression syntax.
An example directives file looks like:
\begin{verbatim}
sub_replace read
#
# match
# was
# becomes
root:x:0:0:root
root:x:
root::
\end{verbatim}
\noindent This example might be run when the {\tt su} command is captured in the debugger.

\item {\tt script\_replace <operation>}-- Replace a substring within a script buffer with a given string.
The intended use is to dynamically modify commands read from script files. Some implementations read 8k
from the script file, operate on the next no-comment line, and then advance the file pointer and repeat.  This causes your Dmod target to be read
many times.  With a script\_replace Dmod, the target match is only considered when it matches the start
of the first non-comment line of a read buffer. 
The directives file includes one or more sets of directives.
The directives use regular expression syntax.
An example directives file looks like:
\begin{verbatim}
script_replace read
#
# match
# was
# becomes
modprobe e1000e
modprobe e1000e
modprobe e100
\end{verbatim}
\noindent This example might be run when the {\tt su} command is captured in the debugger.

\item {\tt full\_replace <operation>} -- Replace the entire write or read buffer with a given string.
The directives file includes a single directive whose replacement string may include multiple lines.
\begin{verbatim}
full_replace write
KERNEL=="eth*", NAME="eth
SUBSYSTEM=="net", ACTION=="add", DRIVERS=="?*", ATTR{address}=="00:e0:27:0f:ca:a8", \
  ATTR{dev_id}=="0x0", ATTR{type}=="1", KERNEL=="eth*", NAME="eth0"

# PCI device 0x8086:0x1001 (e1000e)
SUBSYSTEM=="net", ACTION=="add", DRIVERS=="?*", ATTR{address}=="00:e0:27:0f:ca:a9", \
  ATTR{dev_id}=="0x0", ATTR{type}=="1", KERNEL=="eth*", NAME="eth1"
\end{verbatim}

\item {\tt match\_cmd <operation>} Execute a list of Simics commands when the trigger string is found
in a read or write buffer (per the {\tt <operation>} field), and a separate substring is also found.  If the trigger string is
found, the function will terminate, i.e., no more {\tt write} syscalls will be evaluated.  Simics commands may reference
CLI variables defined via the RESim configuration files, such as network connection names described in \ref{networks}.
\begin{verbatim}
match_cmd write
#
# match (regx)
# was (regx)
# cmd
KERNEL=="eth\*", NAME="eth
("00:e0:27:0f:ca:a8".*eth1|"00:e0:27:0f:ca:a9".*eth0)
disconnect $VDR_eth0 $VDR_switch0
disconnect $VDR_eth1 $VDR_switch1
connect $VDR_eth0 cnt1 = (switch1.get-free-connector)
connect $VDR_eth1 cnt1 = (switch0.get-free-connector)
\end{verbatim}
\end{itemize}

\subsubsection{Dynamic modifications to multiple computers}
Dynamic modifications (Dmods) to system state are often performed early in the boot process, e.g.,
as network devices are being assigned addresses or kernel modules are being loaded.
When simulated components boot, RESim monitors them to determine when each has booted far enough
for the current task record to be of use, which is typically when the {\tt init} process runs.
RESim then pauses after all computers in the simulation have reached this initial state.  Note though that
the first computers to have reached their initial state will continue on while other computers are still
booting.  Thus, by the time RESim pauses, some computers may have executed beyond the point
at which a dynamic modification was desired.

To avoid such race conditions, the RESim configuration file can optionally include the {\tt DMOD} directive
to identify Dmod files for each of the computers in a simulation.  If present, the {\tt runToDmod} command is executed
as soon as the corresponding computer reaches its initial state.  This ensures that dynamic modifications
to those computers will occurr while other computers in the simulation continue to boot to their 
initial states.

\subsubsection{Dmods in the background}
\label{background_dmod}
When dynamically analyzing a process or family of threads, RESim generally manages breakpoints for just those processes.
This optimization can significantly speed up the analysis processes by entirely ignoring system calls and other events
that occur in processes other than those under analysis.  However, there are times when you need to dynamically modify some other
process while debugging.  Consider this example: you've directed RSim to debug some program X, and RESim has now detected
the loading of X and has broken execution.  You now want to observe X, e.g., tracking its I/O to some socket, however you
know that at some point in the coming system execution, some other process Y will write a value that X will observe (perhaps
indirectly).  Use of the {\tt background=True} option with the {\tt runToDmod} command will cause RESim to monitor all
system calls associated with the Dmod, even while you focus on the behavior of X. 


\section{Tracking data}
\label{tracking}
RESim provides several functions for tracking data consumed by processes.  A {\tt Data Watch} data structure tracks input buffers into which
data is read, e.g., automatically as the result of a {\tt runToIO} command.  The {\tt watchData} command causes the simulation to proceed until any of the
{\tt Data Watch} structures are read -- and also lets the analyst create new Data Watches. The {\tt showDataWatch} command displays the current list in
terms of starting address and length. 
The {\tt trackIO} command automates iterations of {\tt watchData} commands, creating a list of execution
points at which {\tt Data Watch} structures are read. The resulting {\tt Watch Marks} are bookmarks that can be view using {\tt showWatchMarks} and
skipped to using the {\tt goToDataMark} command, naming the index.   The IDA client displays these in its {\tt data watch} window.
The {\tt trackIO} function also dynamically creates new {\tt Data Watch} structures as input buffers are copied into other buffers.  It recognizes (some) common
data copy functions, (e.g., memcpy and strcpy). 

The {\tt trackIO} uses a \textit{backstop} value to determine when to stop looking for additional input or references to Data Watch buffers.  The value is in 
cycles, and thus useful values can vary wildly between environments.  Use the {\tt BACK\_STOP\_CYCLES} value in the RESim configuration file to adjust this.
To track multiple packets, simply send them one after another before the backstop is hit.  The backstop is not employed until the first read on the given
FD is encountered (so no reason to hurry your network traffic).  The backstop is cleared whenever it is hit. 

Note that in many situations, by the time the backstop is hit, the thread has invoked a syscall.  If it is a blocking recv, then the next {\tt trackIO} 
command will back up until prior to that system call so that it can properly record and track the call.

Once a trackIO is performed and you've reviewed input data references, you can repeat the tracking step with modified data:
\begin{itemize}
\item Skip the simulation to the point at which the original data was read, e.g., following the recv syscall.  So this by double clicking
on that Watch Mark, or use the goToDataMark function in RESim.
\item Use modifyMemory to change data in memory.  Note this will reset the reverse execution bookmarks, preventing you from skipping to
any earlier point.
\item Use the retrack function.
\item You may repeat this as many times as needed, however instead of skipping to a Watch Mark, you can simply skip to the {\tt origin}
bookmark since that is now the point at which you previously modified memry.
\end{itemize}

\section{Example workflows}
\ref{example-workflows}
\subsection{Watch consumption of a UDP packet}
Open a pcap with Wireshark. Select the data of the packet, right click and export the selected packet bytes into your simics workspace.
Start the monitor and map the desired port to a real ethernet device.
Debug the desired process/pid, e.g., {\tt @cgc.debugPidGroup(875)}.  Track the IO, e.g., {\tt @cgc.trackIO(14)},
then cat the packet, e.g.,
\begin{verbatim}
    cat mypacket > /dev/udp/127.0.0.1/60005
\end{verbatim}

Start IDA with the desired program.  Attached to the process and run the rev.py plugin.  Then go to the ``data watch'' window and
refresh.  That will list all instances of references to the content of the UDP packet. 

\subsection{Reverse engineer a service}
This example assumes you want to understand how a program consumes
data on a specific TCP port.

\begin{itemize}
\item Run the monitor on a configuration having the target and a driver.

\item Use traceAll to generate a system call trace and the showProcTrace() to generate
a process trace file.

\item Use the postscripts/genRpt.sh to generate trace reports,
and look at the resulting network information noting the
program that binds to a port of interest.

\item Create a simple python client script and use
script-driver.sh to copy that to the driver and
run it in the background when the driver boots.
This client should connect to the target port
and perhaps send a string and read the response.
Use a connect loop so the program does not die if the
first connections fail due to the target not yet being ready.

\item Restart RESim and debugProc the target program.

\item Use runToBind and observe the FD (either in the log
or using idaMessage)

\item Use runToAccept, which will not return until the client
connects to the service.  Observe the resulting FD.

\item Use trackIO to note where input is processed.  The stack
may reflect a call to clib from some other library.  Note
you may be in a thread that started in that library.  Use
showSOMap to determine the address at which
the library is loaded.

\item Open the program or the library file in IDA and use the dumpFuns.py script to
generate a function map for the library using is initial base
addresses.

\item If a library was loaded, use edit/segments/rebase to rebase the program from the load address
observed via showSOMap.

\item Use retrack (or injectIO) to re-run the data tracking to pick up calls to mem functions such as memcpy.

\item Attach IDA's debugger to the service and work through the dataWatch list of Watch Marks.

\item Modify data to alter execution paths using either modifyMemory followed by {\tt retrack}, or the injectIO function (the latter
is only available as a RESim command.)  The injectIO command is most efficient and allows you to alter inputs and see
the results without restarting the simulation or restarting IDA (other than to switch libraries.)

\item Use the mapCoverage function to inventory which basic blocks are hit, and to inventory "branches not taken."

\item Stack traces displayed in IDA may lack funtion names -- and may even lack disassembly -- depending on the program or
library loaded into IDA.  You can often still get a decent stack trace using the {\tt stackTrace} command in RESim.

\end{itemize}

\subsection{Observe changes in ouputs}
Use {\tt traceAll} followed by {\tt traceFD} to observe program output in respones to varying inputs injected
via {\tt injectIO} with {\tt stay=True}. TBD, combine commands or make modal? -- for now, must repeat: injectIO;
traceAll; traceFD.  This can be more efficient and less complicated than trying to alter inputs of a client and then
observing responses from the server. 

\subsection{Track buffer accesses}
You've found a buffer populated with data, and you'd like to track access to the buffer just
like you trackIO.  Use the IDA "add data watch" to add the buffer, and then use retrack.

\section{Implementation strategy}
This section discusses our approach to implementing RESim, and some implications for the analyst.
RESim primarily gathers information about a system through monitoring of events, i.e., observed via callbacks tied to 
breakpoints.  Two key features of RESim enable its flexibility and performance.  
\begin{enumerate}
\item Other than basic task record structures, the implementation has very little knowledge of kernel internals.
This is a key design goal.  
\item RESim only monitors events when directed to do so.
\end{enumerate}
\noindent Implications of these design properties can be seen by considering example sessions.  Assume you boot a system in RESim and let it run a bit without
directing any analysis.  The {\tt tasks} directive will list currently running tasks.  However, RESim would have no knowldege of full program names and arguments
provided to execve.  In this example, directing RESim to debug a currently running PID results in a debug session with limited stack traces because
it would not have information from the ELF header\footnote{Unless used with the IDA client}  or shared object map information.  It would not have
information about open files.
That information would be collected if the {\tt traceAll} directive were used, or, for a single program, the {\tt debugProc} directive were used prior to the
process start.

RESim maintains information it has gathered, and does so across debug sessions and across checkpoints written via {\tt writeConfig}.  For example, if you
use {\tt debugProc} to isolate a program, and then stop debugging that program and then return to it, the shared object information is maintained.

Other than IDA analysis, we do not maintain state across different sessions (i.e., sessions not bridged by a {\tt writeConfig} and {\tt RUN\_FROM\_SNAP} snapshot directive.
Shared object maps vary by alsr.

\section{Troubleshooting}
RESim is under ongoing development and does not have a robust regression testing system.  So there will be bugs.
Check the logs, both the RESim log (currently noname.log in /tmp/monitors) and others such as /tmp/revToCall.log
RESim bugs, e.g., Python errors, are often masked when driving from the IDA Client.  When things seem broken, they
may well be.  Redo what fails using the RESim command line, and you may see the error.

Stack traces in RESim are sometimes better than in IDA (though RESim is responsible for both).

\pagebreak
\appendix
\section{Analysis on a custom stripped kernel}
Use of external analysis, (i.e., observation of system memory during system execution, to track application processes), requires some knowledge of kernel data structures, e.g., the location of the current task pointer within global data.   While this information can be derived from kernel symbol tables, some systems, e.g., purpose-built appliances, include only stripped kernels compiled with unknown configuration settings.

Within 32-bit Linux, the address of the current task record can be found either within a task register (while in user mode), or relative to the base of the stack while in kernel mode.  Heuristics can then be used to locate the offsets of critical fields within the record, e.g., the PID and comm (first 16 characters of the program name).  While the current task record provides information about what is currently running – it cannot be efficiently used to determine when the current task has changed.  For that, the RESim tool prefers to know the address of the pointer to the current task record, i.e., the address of the kernel data structure that is updated whenever a task switch occurs.

Once we have the address of the current task record, a brute force search is performed starting at 0xc1000000, looking for that same value in memory.  This search resulted in two such addresses being found, and use of breakpoints indicate the one at the higher memory location is updated first on a task switch. 

On 64-bit Linux kernels, the current task pointer is maintained in GS segment at some processor-specific offset.  This offset is not easily determined – even from source code (see the arch/x86/include/percpu.h use of “this\_cpu\_off”).  A crude but effective strategy for determining the offset into GS is to catch a kernel entry, and then step instructions looking for the ``gs:'' pattern in the disassembly.  The first occurrence of ``{\tt mov rax,qword ptr gs:[}''  seems to be the desired offset.  It is expected that this will vary by cpu. The getKernelParams utility needs to be updated for multi-processor (or multicore) systems.

Once the address containing the pointer to the current task record address is located, the {\tt getKernelParam} utility uses hueristics and brute force to
find the remaining parameters.

\section{Detecting SEGV on a stripped Linux Kernel}
\label{SEGV}
This note summarizes a strategy for catching SEGV exceptions using Simics while monitoring applications on a stripped kernel, i.e., where no reliable symbol table exists and {\tt /proc/kallsyms} has not been read.  In other words, this strategy does not rely on detecting execution of selected kernel code, e.g., signal handling.

Simics can be trivially programmed to catch and report processor exceptions, e.g., SIGILL.  However, the hardware SEGV exception does not typically occur in the Linux execution environment.  Rather, a page fault initiates a sequence in which the kernel concludes that the task does not have the referenced memory address allocated, and thus terminates the task with a SEGV exception.

When a page fault results from a reference to properly allocated memory in Linux, there is no guarantee that the referenced address has a page table entry. In other words, alloc does not immediately update page table structures --it is lazy.  Thus, lack of a page table entry at the time of the fault is no indication of a SEGV exception.  Our strategy must therefore account for modifications to the page table.

When a page fault occurs, we check the page table for an associated entry. If there is not an entry, then we set a breakpoint (and associated callback) on the page table entry, or the page directory entry if that is missing.  We also locate the task record whose next field points to the faulting process, and set a breakpoint on the address of the next field.  If the fault causes a page table update, it is assumed the memory reference is valid.  On the other hand, if a modification is made to the next field before a page table update occurs, we assume the modification is part of task record cleanup due to a SEGV error.

\subsection{Faults on ARM}
The x86 case seems simple compared to what is found in ARM, whose exceptions include "Data Abort"; "Prefetch Abort"; and "Undefined Instruction".  
Data references to unmapped pages yield a Data Abort; while instruction fetches yield a Prefetch Abort.  The "Undefined Instruction" is not necessarily fatal --
for example we see the vmrs (some floating point transfer) a lot.

Data Aborts lead to page handling, unless it does not.  Of interest is that it can lead to references from the kernel to addresses provided by user space.

\section{External tracking of shared object libraries}
During dynamic analysis of a program, the program may call into a shared object library, and the user may wish to analyze the called library.  This note summarizes how RESim provides the user with information about shared object libraries, e.g., so that the target library can be opened in IDA Pro to continue dynamic analysis.  This strategy does not require a shell on the target system, nor does it require knowledge that depends on a system map, e.g., 
synthesizing access to {\tt /proc/<pid>/map}

When the program of interest is loaded via an execve system call, breakpoints are set to catch the open system call.  The resulting callbacks look for opening of shared library files, i.e., *.so.*.   When shared objects are opened, breakpoints are then set to catch the next use of mmap by the process.  We assume the resulting allocated address is where the shared object will be loaded.  Empirical evidence indicates this simple brute force strategy works.  These breakpoints and callbacks persist until the process execution reaches the text segment of the program.

RESim maintains maps of addresses of shared library files.  Use the {\tt showSOMap} command to view a list of libraries and their load
addresses.  The {\tt stackTrace} command identfies the library of the current stack frame (or {\tt show} for the current instruction address.
Once you know the library and its load address, open the library in IDA (and use {\tt dumpFuns.py} and {\tt findBlocks.py} to generate databases
referened by RESim if not yet created). Rebase the program ({\tt Edit/Segment/rebase} and then attach to the debugger.
Switching between libraries currently requires that you exit IDA and then open the other library.

%When a shared object is called, the IDA Pro client retrieves the shared library name from the RESim server and displays it for the user.  When the user opens that file in IDA Pro, and attaches the debugger, the IDA Pro plug-in retrieves the address of the library and causes IDA to rebase using that offset.

\section{Analysis of programs with crude timing loops}
\label{maze}
Consider a program that reads data from a network interface by first setting the socket to non-blocking mode and then looping on a read system call until 30 seconds have expired.  The program spins instead of sleeping.  It calls "read" and "gettimeofday" hundreds of thousands of times.

Creating a process trace on such a program could take hours (or days) because the simulation breaks and then continues on each system call.  This note describes how RESim identifies this condition as it occurs, and semi-automated steps it takes to disable system call tracing until the offending loop is exited.  

While tracing system calls of a process, invocations of "readtimeofday" are tracked and compared to a frequency threshold.  When it appears that the program is spinning on a clock, the user is prompted with an option to attempt to exit the loop. If the user so chooses, RESim will step through a single circuit of the timing loop, recording instructions at the outermost level of scope. It then searches the recorded instructions to identify all conditional jump instructions, and their destinations. Each destination is inspected to determine if it was encountered within the loop.  If not, the destination and the comparison operator that controlled the jump is recorded.  Breakpoints are set on each such destination address.  We then disable all other breakpoints, e.g., those involved in tracing and context management, and run until we reach a breakpoint.  
This feature is called a \textit{maze exit}.  If you would like to avoid the prompts, use the {\tt @cgc.autoMaze()} function to cause the system
to automatically try ot exit mazes as efficiently as it can.

RESim includes an optional function to ensure that the number of breakpoints does not exceed 4 (the quantity of hardware breakpoints supported by x86).  If more than 4 breakpoints are found the analyst can guide the removal of breakpoints. RESim will automatically execute the loop a large number of times in order to identify comparisons that may be converging.  And the user is informed of those to aid the reduction of the quantity of breakpoints.  (Note that in the context of this issue, there are less than or equal to 4 breakpoints and more than 4.  There is probably a lot more than 4 as well, but we've not yet quantified its effects.)

\section{Breakpoints can be complicated: Real and virtual addresses}
\label{external}
Use of a full system simulator enables \textit{external} dynamic analysis of the system.  The analysis is said to be
“external” because the analysis mechanism implementation, e.g., the setting of breakpoints,  does not 
share processor state with the target.
A distinguishing property of external dynamic analysis is that the very act of observation has no effect on the target
system.  This lack of shared effects improves the real-world fidelity of the observed system, but it can also complicate the
analysis, particularly when referencing virtual addresses. 

This property of external analysis is illustrated by tracing an “open” system call. 
Assume the simulator is directed to break on entry to kernel space.  At that point, we can observe the value
of the EAX register and determine if it is an “open” call.  We can then observe and record the
parameters given to the open system call by the application.  However, the name of the file to open
is passed indirectly, i.e., the parameters contain an address of a string.  How might we record
the file name rather than just its address?   

Requesting the simulator to read the value at the given virtual address of the
file name will not always yield the file name because the
physical memory referenced by the virtual address may not yet have been paged into RAM by the target operating system.
If the analysis were not external, then the mere reference to the virtual address could result in the
operating system mapping the page containing the filename.  An external analysis has no such side effects.

The simulator includes different APIs for reading virtual memory addresses and reading physical memory addresses.
The former mimics processor logic for resolving virtual addresses to physical addresses based on page table
structures. Attempts to read virtual addresses that do not resolve to physical addresses result in exceptions reported
by the simulator -- they do not generate a page fault.

Waiting to read from the file name's virtual address until after the kernel has completed the system call, i.e.,
until the kernel is about to return to user space, would ensure the virtual address containing the string
will have been paged in.  However, that strategy is susceptible to a race condition in which the file
name is changed after the kernel has read it but before the trace function records it.  This may occur
if the file name is stored in writable memory shared between multiple threads, and could result in a trace function
failing to record the correct file name used in an open system call.
 
Since we know the kernel will have to read the file name in order to perform the open function, we
can set a breakpoint on the virtual address of the file name, and then let the simulation continue. 
When the kernel does reference the address, the simulation will break.  In some implementations, the
memory will still not have been paged in, (e.g., the kernel's own reference to the address generates a page fault),
but leaving the breakpoint in place and continuing the simulation
will eventually allow us to read the file name as the kernel is itself reading it.  Except, that is true for only 
for 32-bit kernels.  64-bit kernels only reference physical addresses when reading filenames from pages that had
not been present at the time of the system call.  In other words,
in 64-bit Linux, breakpoints may never be hit when set on the virtual address of a file name referenced in an open call.

Even though the kernel is able to read the file name without ever referencing its virtual address, the kernel does
need to bring the desired page into physical memory so that it may read the file name.  In doing so, the kernel
updates the page tables such that references to the virtual memory address will lead to the file name in
physical memory – even though such a reference may never happen.  RESim takes advantage of the kernel's
page table maintenance by setting breakpoints on the paging structures referenced by the virtual address.
In some cases, the target page table may not be present at the time of the system call, so we must first
break on an update to a page directory entry, and then later break on an update to the page table entry,
finally yielding address of the page in physical memory.

Note this property of the 64-bit Linux implementation has implications beyond tracing of system calls.  A reverse
engineer may wish to dynamically observe the opening of a particular file name observed within an executable image.
Setting a "read" breakpoint on the virtual address of the observed file name would fail to catch the open function
on 64-bit Linux, while it would have caught the open on 32-bit Linux.

\section{Divergence Between Physical Systems and RESim Simulations}

\subsection{Overview}
This appendix identifies potential sources of divergence between RESim models and
real world systems and presents some strategies for mitigating divergence.  
Models that lack fidelity with target hardware may lead to divergent execution of software.
Consequences can range from scheduling differences, (which generally also diverge between
boots of the same hardware), to substantially different behavior between the model and
the physical system.
For example, on some boots of a simulation, a set of Ethernet devices may be assigned incorrect names, e.g., ``eth0''
is assigned to the device that should be ``eth1''.  In some cases, these
divergences can be 
mitigated if detected.  In our example, if the eth0/eth1 are found to have been
swapped, then reversing their corresponding connections to switches might mask the problem,
restoring fidelity between the simulation and the physical system.  (See \ref{dmod}.)

\subsection{Timing}
Simics processor models execute all instructions in a single machine cycle.  The quantity
of machine cycles required to execute instructions varies by instruction on real processors.
Most designs for concurrent process execution do not rely on cycle-based timing.  However,
race conditions that appear on real systems may manifest differently on simulated systems.

\subsection{Model Limitations}
It is not always practical to obtain a high fidelity model of every component in a target system.  
Models may lack specific peripheral devices expected by a kernel.  In some cases, functionally
compatable devices can be substituted for missing peripherals.  For example, the kernel image from an
X86 target may include drivers for existing Simics ethernet devices, and yet the initialization functions
do not cause the corresponding modules to be loaded -- rather, they load kernel modules for an ethernet 
device that is not modeled.  Use of the Dmod function described in \ref{dmod} can cause the kernel
to load the desired module, without having to modify the disk image.  
TBD: Explore model building, e.g., to simulate an fpga accessed via a PCI bus device.

\subsection{What FD is this?}
You have created a input stimulus and would like to understand the resulting behavior of a specific process
that runs a long time as a service.
Running a full system trace up to the stimulus as a means of getting context may not be practical.  So you start
a {\tt traceAll} at some point prior to the external stimulus.  You then see socket activity on a specific FD.
However the current trace does not include a connection that maps to that FD.  Use the {\tt procTrace.txt}
file to get the pid of the process as it existed in the full system trace.  Then, if you assume the FD will match
that from your full system trace (which may be a fine assumption if the connection is long-term), grep on 
the system call trace, e.g.,
\begin{verbatim}
grep "pid:1731" syscall_trace.txt | grep "FD: 11
\end{verbatim}
That gives you the port and address information that you can then search for in the {\tt netLinks.txt} file.

\section{Context management implementation notes}
RESim manages two Simics contexts: the default for the cell, and a ``resim'' context for each cell.
Contexts are managed within {\tt genContextManager.py}. The resim context is used when watching a specific process
or thread family.  Otherwise, the default context is used.  The context of each processor is dynamically altered 
such that breakpoints are only hit when in the corresponding context.  For example, assume we are debugging PID 95
(for simplicity, assume no threads).
Whenever PID 95 is schedule, the processor context is set to resim.  The context is returned to the default whenever
PID 95 is not scheduled.  System call breakpoints set during debugging, e.g., runToWrite, will be associated
with the resim context.  These breakpoints will only be hit when the processor is in the resim context. 
Breakpoints may be set in the default context while debugging, e.g., handle a background Dmod (see \ref{background_dmod}.  Those
breakpoints will not be caught when processor is in the resim context.
TBD: define multiple contexts to allow parallel debugging of different processes on the same cell.  (Parallel 
debugging of processes on different cells should be easier since they each have independent context managers.)


\section{What is different from Simics?}
RESim is based the Simics simulator, including the \textit{Hindsight} product.  It does not incorporate the \textit{Analyzer} product
OS-Awareness functions.  RESim includes its own OS-Awareness functions.  The Simics Analyzer features are primarily intended to aid
understanding and debugging of \textit{known} software, i.e., programs for which you have source code.  RESim is intended to reverse
engineer unknown software, and thus does not assume possession of source code or specifications.

\section{IDA Pro issues and work arounds}
The IDA debugger in 7.2 requests more registers than Simics knows about.  The Simics gdb-remote has been modified
to simply return the value of the highest numbered register that it knows about.  An alternative is to modify
xml files in ~/ida-7.2/cfg to only include desired registers.   For ARM (the qsp-arm), the arm-fpa.xml (from gdb source
tree) needs to be added to the arm-with-neon.xml file in ida/cfg.  The cpsr register (number 25) is not updated by IDA
unless registers are defined for each register value returned by Simics in the 'g' packet.

The IDA debugger in 7.2 uses thread ID 1 when performing the vCont GDB operation.  Hex-rays modified the IDA gdb plugin to
use ID 0, thereby fixingthe problem.

\section{Simics issues and work arounds}
New-style Simics console management causes an X11 error: ''The program 'simics-common' received an X Window System error.''
Use:
\begin{verbatim}
gsettings set com.canonical.desktop.interface scrollbar-mode normal
\end{verbatim}
\noindent to avoid the exception.

\section{Performance tricks}
Use disable-reverse-execution whenever you do not really need reversing, e.g., while moving forward to a known connect or accept
within a program being debugged.

Instead of tracing all from a boot, consider running ahead until the systemd-logind or rsyslogd is created.

\section{New disk images}
For x86, use put the workspace/dvd.simics in targets.  Edit it to name an installation iso.  You may need to change the date in
the file, and run with realtime enabled.  After the install, use save-persistent-state, and then rename the resulting craff as
needed.

When using real networks, configure the image routing and resolv.conf, using your ip address:
\begin{verbatim}
route add default gw 10.10.0.1
echo nameserver 10.10.0.1 > /etc/resolv.conf
\end{verbatim}

\subsection{Driver platforms}
\label{driver}
If building a new driver, use the DRIVER\_WAIT directive in the ini file to prevent RESim from waiting for the driver to finish 
(the driver\_ready.flag) -- at least until you finish configuring a driver.

The driver platform defined by the {\tt RESim/simics/workspace/ubuntu\_driver.ini} example has the Simics Agent pre-installed.  The
{\tt driver-script.sh} in that directory can be copied and modified within your workspace.  The driver will download that shell script and execute
it when booting.  Your target will not boot until that script finishes (and creates the driver-ready.flag file).
Note the simulation will hang while processing that script, so launch any long running programs in the background.

The username and password for that driver are mike/password.  Use {\tt enable-real-time-mode} to avoid login timeouts and network timeouts.

To update the driver, e.g., with new packages, use the driver.ini configuration.  Then use mapdriver.simics to connect to the real network.
You can then use apt-get to get new packages.  And scp to push files onto the machine.  Then use save-persistent-state and the do\_merge.sh to
created a merged craff.  \textbf{Do not} forget to shutdown or sync before saving state!.  Give the driver craff a name that does not conflict with exising names.

Large scp operations may stall.  Consider using the simics-agent to move files to the driver.  However,
these only happen one file at a time, so use tar.

Add the simics-agent from RESim/simics/simics-agent to /usr/bin.  And create a systemd service to run the
driver-init.sh script from the RESim/simics/workspace.  That script bootstraps the driver's ability to pull
and execute the driver-script.sh from the workspace.

\subsubsection{Notes on driver}
Wind River is not very good at networking, as a result, the real-network connect used to update the driver can often stall/hang.
Be prepared to kill apt-gets and retry multiple times.  It will eventually work.

The Python world uses SSL certificates in a manner that leads to breakage.  If pip fils on SSL validation, use the -v option
to find which new python.org server is causing the problem, and use the --trusted-host dog.pythonwhatever.org option on pip.

\section{Simics user notes}
This section includes ad-hoc suggestions for users with little Simics experience.

\begin{itemize}
\item Simics documentation is in the doc directory relative to workspace directories.

\item See the \textit{ethernet...} manual for connecting real networks.

\item Use wireshark <switch> to see traffic going through one of the switches.

\item The enable-realtime-mode prevents the simulation from running faster than real time.  Useful when trying to login
to a virtual console, or avoid network timeouts.  Also useful when working remotely and you cannot get a ctl C in 
edgewise.

\item The "x" command at the simics command line displays memory values.  Use "help" and "apropos" to find other commands of interest.

\item To save changes made to an OS disk image, use save-persistent-state; and then exit simics and use the bin/checkpoint\_merge command
to create a new craff file (found in the checkpoint directory).

\item To trace all instructions and memory access use:
\begin{verbatim}
load-module trace
new-tracer
trace0.start
\end{verbatim}
\end{itemize}

\section{Implementation notes}
Use the {\tt VT\_in\_time\_order(self.vt\_handler, param)} when you need to know the memory transaction that
led to a stop hap during reverse.  See findKernelWrite for an example.

Take care when using {\tt SIM\_hap\_add\_callback\_range} to ensure your breakpoints are truly in a contiguous range.
Concurrency often results in dis-contiguous allocations of breakpoint numbers with the "holes" subsequently used for other purposes.
Imagine your confusion when a hap is hit for the wrong event.  If needed, issue multiple haps on multiple ranges, watching the
breakpoint sequence numbers as they are allocated.  Simics breakpoint numbers may look like handles, but the hap range allocation 
gives their values semantics.  See the {\tt coverage.py} module for an example.

\section{ToDo}
Catching kill of process uses breakpoints on task record next field that points to the subject process's task rec.  Fails if the
process whose record is watched is killed.  Need to also watch "prev" on the subject process?

Convert traces to csv and explore data presentation strategies for navigating processes and IPC.

Feature to flexibly identify user-space libraries to be traced.

Test Simics 7 changes to ensure they work on older Simics; ifdef if necessary.

Enhance the {\tt dataWatch} function detect generic C++ string allocator, and expand watch.

Tracking memory-mapped IO is not directly supported.  Perhaps catch the mmap function call and somehow determine it is mmio purposed.  Then
set breakpoints...

\subsection{Missed threads when debugging}
When a process is identified for debugging, e.g., via debugPidGroup, RESim attempts to include actions by all threads in the thread group.  It uses the
TrackThreads class to catch clones of the process.  Also, the genContextManager watches for scheduling of unknown pids having the comm of the debugging
pid.  We can perhaps remove the tracking of clones from TrackThreads?

\subsection{I/O via threads}
Network traffic is sometimes sent via a thread, making it challenging to track the source of the data that was sent.  Breaking on a "sendto" may
lead to a thread that only does the sendto, with the parameters coming from a clone setup.  Thus, you must find which pid does the send to and then
runToSyscall until that pid is created.

\subsection{Tracing library calls}
It should be straight foward to instrument selected relocatable functions or statically linked functions.
May be tempting to do that for malloc -- but on the other hand, if you have the address of the start of a buffer, then reverse tracking that
will generally lead to the malloc call.

\subsection{Backtracing malloc'd addresses}
You have the address of a buffer you think was malloc'd; you back trace, which stops in malloc.  You think you found it, look at the call stack and
declare success.  You may be wrong.  You may be looking at the malloc that happened prior to the malloc of interest.  For example, if you are looking
for the source of a memory location whose value is 0xf4938, RESim may find that in malloc, and then happily continue to back trace until it finds
the creation of value 0xf4930  -- just in increment, right?  So, look at your cycles and notice large gaps.
Add a "value" field to the bookmark printout to make it more obvious when a permutation on the desired value is being reported.

%\subsection{Lies about ARM syscall return values}
%Documents suggest syscall return values are in R0.  That may be, but they are also in R7 -- and libc seems to use what is in R7.
%This matters when adjusting recv counts using injectIO.  TBD --- revisit this.  ARM5 does not seem to do this?

\subsection{Watching process exit whilst jumping around time}
We try to catch page faults, or other events that lead to process death.  This is performed in the ContextManager.  
This mechanism is also central to catching access violations.  The mechanism works fine moving forward from a clean state.  But
how does it behave if we jump backward to an arbitrary time, e.g., prior to the demise of a now dead process?  A new ContextManager function
will reset all process state to that currently observed.  TBD, also modify tracers to ignore events that occur prior to end of recording?


\subsection{Defining new targets}
System names are defined by assigning {\tt "name = whatever"} within the ...system.include file's line that creates the component, typically the board.
Simics parameters are typically ONLY added to the script file in which they are used, and then sucked in by the calling scripts using params from.
Systems scripts error reporting is sparse and tedious.   Copy the needed Simics scripts from their distribution directory into simics/simicsScripts/targets,
and change the simics env variable to scripts where needed -- or remove preface and use relative file if local. 

\subsection{Real networks: WARNING}
Simics supports traffic between the simulation and a real network using {\tt connect-real-network} commands and related commands using a \textit{service node}.
This can be useful to quickly generate new packets and send them to the target, but without needing to interact with a driver component.
Note however that Simics has limitations on the use of real networks when reverse execution is enabled.  Some of these limitations can lead to silent corruption
of the simulation.  Others to crashes.  An obvious limitation is that you cannot replay periods in which real network traffic was received (though Simics supports a different IO replay feature).

Most problems related to real network can be avoided by connecting the real network prior to enabling reverse execution, e.g., via a debugProc command.
Use the {\tt INIT\_SCRIPT} ENV directive in the init file to specify a simics script to load at the start of each session.

\subsection{Tracing calls already made}
Consider a system that has been run to a state at which the analyst wishes to commence tracing all calls made by a thread group.  Any call currently
waiting in the kernel for data will not make it into the trace because we catch parameters on the call and tracing has not yet commenced.
We can look at the sysEnter frames managed by reverseToCall, and manufacture system exit calls.  A partial example was done for trackIO (not yet used, we currently
just back up prior to the syscall for that.)

\subsection{Fork exit}
A fork followed by an exit may result in the exit occuring before the child is ever scheduled.

\subsection{Code coverage (in process)}
\label{coverage}
Features to reflect code coverage should support human analysis as well as automated analysis, e.g., fuzzing.  To support the human, coverage is highlighted within IDA using color-coded
basic blocks.  The scope of coverage is tied either to the text segment, i.e., the program, or a single shared library.  We refer to this as a \textit{coverage unit}..  
Coverage tracking commences with use of the {\tt mapCoverage} command and is intended to aid understanding of program response to inputs tracked via 
the {\tt trackIO} or {\tt injectIO} commands.  Those basic blocks which are only hit between coverage commencement and the first input event are separately colored so as to not
be confused with blocks hit subsequent to receipt of input.  This distinction is intended to facilitate comparisons between \textit{data sessions} defined as periods
between receipt of input (or IO injection) and quiescence with respect to the backstop logic.
Within the IDA display, coverage properties of basic blocks will be
coded into five colors:
\begin{itemize}
\item Never executed.
\item Never executed during a data session
\item Executed during a data session, but not during this data session
\item Executed during this session and some previous data session.
\item Executed only during this data session.
\end{itemize}

The {\tt coverage} module maintains three data files for each coverage unit: a running total set of hits from previous data sessions; the hits for the most recent data session;
and hits which occur prior to the first input data reference (e.g., reads, selects, etc).  The running total is only updated immediately prior to the start 
of a new data session.  At the start of each data session, the coverage module will restore any breakpoints found
in the recent session data file and then merge it into the running total.  The coverage module will then clear its internal hits data.  The IDA client {\tt injectIO} command will first
reset all basic block colors.  When the simulation stops, the IDA plugin will read the three hits files and color blocks accordingly.  The running hits file is intended to persist across
RESim sessions.  

\subsubsection{Branches not taken}
The IDA client generates a list of basic block branches that were not taken, i.e., unused exits from hit basic blocks.  This list is presented in the {\tt BNT} window of the IDA client
and is intended to help the analyst see places where changes in input data may have resulted in added coverage.  Double-clicking on an entry will take the simulation to the corresponding 
cycle.  Note this is only available for the very first coverage hit of each basic block.


Initially, no database of hits will be maintained tying data files to hit sets.  A downside is that if a data file is consumed twice, the analyst no longer sees
which basic block hits are unique to that data file. Each subsequent data session artifacts are additive, and the effects of any previous runs cannot independently viewed.

\subsubsection{Coverage for fuzzing}
Assume we'd like to repeatedly record coverage from the same starting point, but with varying inputs.  What is the trade-offs between
restoring a checkpoint (which enabling reverse execution) and restoring a bookmark?

How to feed different input sets to each iteration of the simulation?  Pass a directory of files?

Start with initial case trimming.  Reduce input data to minimal that still chances state.

\subsection{Real networks and UDP}
Using {\tt cat foo > /dev/udp/localhost/60060} is fine for a single packet.  However multiple packets seem to get lost unless brief sleeps are
added between the cat commands.


\end{document}

